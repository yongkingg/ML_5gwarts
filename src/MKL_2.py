import os
import cv2
import pandas as pd
import numpy as np
from tqdm import tqdm
from skimage.feature import hog
from skimage.filters import gabor
from sklearn.model_selection import train_test_split
from sklearn.svm import SVC
from sklearn.metrics import accuracy_score
from sklearn.preprocessing import StandardScaler, LabelEncoder
from sklearn.metrics.pairwise import linear_kernel, chi2_kernel
import sys
import io
import pickle
import warnings
import matplotlib.pyplot as plt

warnings.filterwarnings('ignore')

# ============================================================
# 1. Feature Extraction Functions (ë™ì¼)
# ============================================================

def extract_hsv(img_bgr):
    img_hsv = cv2.cvtColor(img_bgr, cv2.COLOR_BGR2HSV)
    hist = cv2.calcHist([img_hsv], [0, 1, 2], None, 
                        [8, 8, 8], [0, 180, 0, 256, 0, 256])
    hist += 1e-6
    cv2.normalize(hist, hist)
    return hist.flatten()

def extract_hog(img_bgr):
    img_gray = cv2.cvtColor(img_bgr, cv2.COLOR_BGR2GRAY)
    img_resized = cv2.resize(img_gray, (128, 128)) 
    return hog(img_resized, pixels_per_cell=(8, 8),
               cells_per_block=(2, 2), visualize=False)

def extract_sift_avg(img_bgr):
    img_gray = cv2.cvtColor(img_bgr, cv2.COLOR_BGR2GRAY)
    try:
        sift = cv2.SIFT_create()
        kp, des = sift.detectAndCompute(img_gray, None)
        if des is not None and len(des) > 0:
            return np.mean(des, axis=0)
        return np.zeros(128)
    except:
        return np.zeros(128)

def extract_orb_avg(img_bgr):
    img_gray = cv2.cvtColor(img_bgr, cv2.COLOR_BGR2GRAY)
    try:
        orb = cv2.ORB_create(nfeatures=500)
        kp, des = orb.detectAndCompute(img_gray, None)
        if des is not None and len(des) > 0:
            return np.mean(des.astype(np.float32), axis=0)
        return np.zeros(32)
    except:
        return np.zeros(32)

def compute_gist_gray(img_bgr):
    IMG_SIZE = 256
    N_BLOCKS = 4
    ORIENT = [8, 8, 8, 8]
    FREQ = [0.05, 0.10, 0.20, 0.40]
    
    img_gray = cv2.cvtColor(img_bgr, cv2.COLOR_BGR2GRAY)
    img_resized = cv2.resize(img_gray, (IMG_SIZE, IMG_SIZE)).astype(np.float32) / 255.0
    feats = []
    
    for freq, n_ori in zip(FREQ, ORIENT):
        for k in range(n_ori):
            theta = k * np.pi / n_ori
            real, imag = gabor(img_resized, frequency=freq, theta=theta)
            magnitude = np.sqrt(real ** 2 + imag ** 2)
            h, w = magnitude.shape
            bh, bw = h // N_BLOCKS, w // N_BLOCKS
            
            for by in range(N_BLOCKS):
                for bx in range(N_BLOCKS):
                    block = magnitude[by*bh:(by+1)*bh, bx*bw:(bx+1)*bw]
                    feats.append(block.mean())

    return np.asarray(feats, dtype=np.float32)

# ============================================================
# 2. MKL í—¬í¼ í•¨ìˆ˜ (L1/L2 ê³µí†µ)
# ============================================================

def compute_objective(alpha_y_sv, K_combined_sv):
    """SVM ë“€ì–¼ ëª©ì  í•¨ìˆ˜ J(d) ê³„ì‚° (ê³µí†µ)"""
    dual_term = np.dot(alpha_y_sv, np.dot(K_combined_sv, alpha_y_sv))
    sum_alpha = np.sum(np.abs(alpha_y_sv))
    return sum_alpha - 0.5 * dual_term

def compute_gradient(alpha_y_sv, K_list_sv):
    """J(d)ì˜ ê·¸ë˜ë””ì–¸íŠ¸ dJ/dd ê³„ì‚° (ê³µí†µ)"""
    grad = []
    for K in K_list_sv:
        grad.append(-0.5 * np.dot(alpha_y_sv, np.dot(K, alpha_y_sv)))
    return np.array(grad)

def compute_current_J(d, K_list_train, y_train, C):
    """í˜„ì¬ dì— ëŒ€í•œ SVMì„ í’€ê³  ëª©ì  í•¨ìˆ˜ ê°’ J(d) ë°˜í™˜ (ê³µí†µ)"""
    K_comb = np.zeros_like(K_list_train[0])
    for i in range(len(d)):
        K_comb += d[i] * K_list_train[i]

    svm = SVC(kernel='precomputed', C=C)
    svm.fit(K_comb, y_train)

    sv = svm.support_
    if len(sv) == 0:
        return 0

    alpha_y = svm.dual_coef_[0]
    K_sv = K_comb[np.ix_(sv, sv)]

    return compute_objective(alpha_y, K_sv)


# ============================================================
# 3. [ì‹ ê·œ] L2-Norm (Ridge) MKL í—¬í¼ ë° í›ˆë ¨ í•¨ìˆ˜
# ============================================================

def ridge_line_search(d, D, grad_J_new, K_list_train, y_train, C, lambda_ridge):
    """
    L2-MKL (Ridge)ì„ ìœ„í•œ Backtracking Line Search
    - J_new(d) = J(d) + lambda * ||d||^2 ì— ëŒ€í•œ Armijo ì¡°ê±´ì„ ë§Œì¡±í•˜ëŠ” ìŠ¤í…(gamma) íƒìƒ‰
    """
    gamma = 1.0
    alpha = 0.5
    beta = 0.1

    # J_new(d) = J(d) + lambda * ||d||^2
    curr_J = compute_current_J(d, K_list_train, y_train, C)
    curr_J_new = curr_J + lambda_ridge * np.dot(d, d)

    grad_dot_D = np.dot(grad_J_new, D)

    if grad_dot_D > 0:  # í•˜ê°• ë°©í–¥ì´ ì•„ë‹ˆë©´ ì¤‘ë‹¨
        return 0

    while True:
        d_new = d + gamma * D
        d_new[d_new < 0] = 0  # 0 ë¯¸ë§Œì€ 0ìœ¼ë¡œ íˆ¬ì˜ (Positivity)

        new_J = compute_current_J(d_new, K_list_train, y_train, C)
        new_J_new = new_J + lambda_ridge * np.dot(d_new, d_new)

        # Armijo ì¡°ê±´: J_new(d + gamma*D) <= J_new(d) + beta * gamma * (grad_J_new . D)
        if new_J_new <= curr_J_new + beta * gamma * grad_dot_D:
            return gamma  # ì¡°ê±´ ë§Œì¡± ì‹œ ìŠ¤í… ë°˜í™˜

        gamma *= alpha
        if gamma < 1e-10:
            return 0  # ìŠ¤í…ì´ ë„ˆë¬´ ì‘ì•„ì§€ë©´ ì¤‘ë‹¨

def ridge_mkl_train(K_list_train, y_train, C=1.0, max_iter=100, tol=1e-3, lambda_ridge=0.1):
    """
    L2-Norm (Ridge) MKL í›ˆë ¨ í•¨ìˆ˜
    - ëª©ì  í•¨ìˆ˜: min J(d) + lambda * ||d||^2
    - ì œì•½ ì¡°ê±´: d_m >= 0
    """
    M = len(K_list_train)
    N = K_list_train[0].shape[0]

    d = np.ones(M) / M  # 1/Më¡œ ì‹œì‘ (ë‹¨ìˆœ í‰ê· )
    svm_model = None

    print("\nğŸ“Œ L2-Ridge MKL Iteration Progress")
    for it in tqdm(range(max_iter), desc="L2-MKL Optimize"):
        # 1. í˜„ì¬ d (ì •ê·œí™”ë˜ì§€ ì•ŠìŒ)ë¡œ SVM í›ˆë ¨
        K_comb = np.zeros((N, N))
        for m in range(M):
            K_comb += d[m] * K_list_train[m]

        svm = SVC(kernel='precomputed', C=C)
        svm.fit(K_comb, y_train)

        sv = svm.support_
        if len(sv) == 0:
            svm_model = svm
            break

        # 2. L2 í˜ë„í‹°ê°€ ì ìš©ëœ ìƒˆ ê·¸ë˜ë””ì–¸íŠ¸ ê³„ì‚°
        alpha_y = svm.dual_coef_[0]
        K_sv = [K[np.ix_(sv, sv)] for K in K_list_train]
        
        grad_J = compute_gradient(alpha_y, K_sv)  # ì›ë³¸ ê·¸ë˜ë””ì–¸íŠ¸ dJ/dd
        grad_J_new = grad_J + 2 * lambda_ridge * d  # Ridge í˜ë„í‹° í•­ì˜ ê·¸ë˜ë””ì–¸íŠ¸(2*lambda*d) ì¶”ê°€

        # 3. í•˜ê°• ë°©í–¥ (Projected Gradient)
        D = -grad_J_new
        
        # d_m=0ì´ê³  í•˜ê°• ë°©í–¥ë„ ìŒìˆ˜ë©´, 0ìœ¼ë¡œ ê³ ì • (Positivity)
        for m in range(M):
            if d[m] < 1e-10 and D[m] < 0:
                D[m] = 0
        
        # 4. ì¢…ë£Œ ì¡°ê±´ (ê·¸ë˜ë””ì–¸íŠ¸ í¬ê¸°)
        if np.linalg.norm(D) < tol:
            svm_model = svm
            break

        # 5. ë¼ì¸ ì„œì¹˜ (L2ìš©)
        gamma = ridge_line_search(d, D, grad_J_new, K_list_train, y_train, C, lambda_ridge)
        
        if gamma == 0:
            svm_model = svm
            break

        # 6. d ì—…ë°ì´íŠ¸ (ì‹¬í”Œë ‰ìŠ¤ ì •ê·œí™” X)
        d = d + gamma * D
        d[d < 0] = 0  # ìµœì¢… íˆ¬ì˜

    if svm_model is None:
        svm_model = svm

    # ê°€ì¤‘ì¹˜ dëŠ” í¬ê¸° ìì²´ê°€ ìµœì í™”ëœ ê²°ê³¼ (e.g., [0.5, 0.2, 0.1...])
    # í•´ì„ì„ ìœ„í•´ ì •ê·œí™”ëœ ë²„ì „ë„ ë°˜í™˜
    d_normalized = d / np.sum(d) if np.sum(d) > 0 else np.ones(M) / M
    
    return svm_model, d, d_normalized

# ============================================================
# 4. MAIN (L2-MKL ë²„ì „ìœ¼ë¡œ ìˆ˜ì •)
# ============================================================

def main():
    print("--- 1. ë°ì´í„° ì¤€ë¹„ ---")

    try:
        current_script_path = os.path.abspath(__file__)
        base_dir = os.path.dirname(current_script_path)
    except:
        base_dir = os.getcwd()

    data_root_dir = os.path.join(base_dir,"../", "data", "processed")
    print(f"ë°ì´í„° í´ë”: {data_root_dir}")

    if not os.path.exists(data_root_dir):
        print("âŒ processed í´ë” ì—†ìŒ")
        return

    feature_extractors = {
        'hsv': extract_hsv,
        'hog': extract_hog,
        'sift_avg': extract_sift_avg,
        'orb_avg': extract_orb_avg,
        'gist': compute_gist_gray
    }

    kernel_functions = {
        'hsv': chi2_kernel,
        'hog': linear_kernel,
        'sift_avg': linear_kernel,
        'orb_avg': linear_kernel,
        'gist': linear_kernel
    }

    feature_names = list(feature_extractors.keys())
    print(f"ì‚¬ìš© íŠ¹ì§•: {feature_names}")

    # ---------------------------------------------------------
    # 2. Load ALL images (with progress)
    # ---------------------------------------------------------
    print("\n--- 2. ì´ë¯¸ì§€ ë¡œë“œ ---")
    all_images = []
    all_labels = []

    zone_list = sorted(os.listdir(data_root_dir))
    for label in tqdm(zone_list, desc="ğŸ“‚ Load Folders"):
        zone_path = os.path.join(data_root_dir, label)
        if not os.path.isdir(zone_path):
            continue

        for img_name in tqdm(os.listdir(zone_path), desc=f" â†’ {label}", leave=False):
            img_path = os.path.join(zone_path, img_name)
            img = cv2.imread(img_path)
            if img is not None:
                all_images.append(img)
                all_labels.append(label)

    print(f"ë¡œë“œ ì™„ë£Œ: {len(all_images)}ì¥ ì´ë¯¸ì§€")

    le = LabelEncoder()
    y_labels = le.fit_transform(all_labels)

    X_train_imgs, X_test_imgs, y_train, y_test = train_test_split(
        all_images, y_labels, test_size=0.3, random_state=42, stratify=y_labels
    )

    del all_images
    del all_labels

    # ---------------------------------------------------------
    # 3. Feature Extraction with Progress Bar
    # ---------------------------------------------------------
    print("\n--- 3. Feature Extraction ---")

    X_train_features = {name: [] for name in feature_names}
    X_test_features = {name: [] for name in feature_names}

    print("Train feature extraction...")
    for img in tqdm(X_train_imgs, desc="âœ¨ Train Extract"):
        for name, func in feature_extractors.items():
            X_train_features[name].append(func(img))

    print("Test feature extraction...")
    for img in tqdm(X_test_imgs, desc="ğŸ” Test Extract"):
        for name, func in feature_extractors.items():
            X_test_features[name].append(func(img))

    del X_train_imgs, X_test_imgs

    scalers = {}

    # scale transform
    for name in feature_names:
        X_train_features[name] = np.array(X_train_features[name])
        X_test_features[name] = np.array(X_test_features[name])

        scaler = StandardScaler().fit(X_train_features[name])
        X_train_features[name] = scaler.transform(X_train_features[name])
        X_test_features[name] = scaler.transform(X_test_features[name])
        scalers[name] = scaler

    # ---------------------------------------------------------
    # 4. Compute Kernels with Progress Bar
    # ---------------------------------------------------------
    print("\n--- 4. ì»¤ë„ ê³„ì‚° ---")

    K_list_train = []
    K_list_test = []

    for name in tqdm(feature_names, desc="ğŸ”§ Kernel Build"):
        Xtr = X_train_features[name]
        Xte = X_test_features[name]
        kernel = kernel_functions[name]

        if kernel == chi2_kernel:
            minv = Xtr.min()
            if minv <= 0:
                Xtr += -minv + 1e-6
            minv_t = Xte.min()
            if minv_t <= 0:
                Xte += -minv_t + 1e-6

        K_list_train.append(kernel(Xtr, Xtr))
        K_list_test.append(kernel(Xte, Xtr))

    # ---------------------------------------------------------
    # 5. [ìˆ˜ì •] L2-MKL Training
    # ---------------------------------------------------------
    print("\n--- 5. L2-Ridge MKL Training ---")

    # lambda_ridge ê°’ì„ ì¡°ì ˆí•˜ì—¬ í¬ì†Œì„±(0)ê³¼ ì¡°í•©(ë¶„ì‚°) ì‚¬ì´ì˜ ê· í˜•ì„ ë§ì¶¤
    # - lambdaê°€ í¬ë©´: ëª¨ë“  dê°€ 0ì— ê°€ê¹Œì›Œì§ (ê°•í•œ L2 í˜ë„í‹°)
    # - lambdaê°€ ì‘ìœ¼ë©´: dê°€ ì»¤ì§ˆ ìˆ˜ ìˆìŒ (L1ê³¼ ìœ ì‚¬í•´ì§ˆ ìˆ˜ ìˆìŒ)
    LAMBDA_RIDGE = 0.1 # <--- ì´ ê°’ì„ 1.0, 0.01 ë“±ìœ¼ë¡œ ì¡°ì ˆí•´ë³´ì„¸ìš”

    svm_model, d_raw, d_normalized = ridge_mkl_train(
        K_list_train, y_train, C=1.0, max_iter=200, tol=1e-4, lambda_ridge=LAMBDA_RIDGE
    )

    print("\nìµœì  ì»¤ë„ ê°€ì¤‘ì¹˜ d (í•´ì„ìš© ì •ê·œí™”):")
    for i, w in enumerate(d_normalized):
        print(f"  {feature_names[i]:<10}: {w:.4f}")

    # ---------------------------------------------------------
    # 6. [ìˆ˜ì •] L2-MKL í‰ê°€
    # ---------------------------------------------------------
    print("\n--- 6. L2-MKL í‰ê°€ ---")

    # ì¤‘ìš”: ì˜ˆì¸¡ ì‹œì—ëŠ” 'ì •ê·œí™”ë˜ì§€ ì•Šì€' raw ê°€ì¤‘ì¹˜(d_raw)ë¥¼ ì‚¬ìš©í•´ì•¼ í•©ë‹ˆë‹¤.
    # L2 MKLì€ ê°€ì¤‘ì¹˜ì˜ 'í¬ê¸°' ìì²´ë¥¼ í•™ìŠµí•˜ê¸° ë•Œë¬¸ì…ë‹ˆë‹¤.
    K_test_comb = np.zeros_like(K_list_test[0])
    for i in range(len(d_raw)):
        K_test_comb += d_raw[i] * K_list_test[i]

    y_pred_mkl = svm_model.predict(K_test_comb)
    print(f"L2-MKL Accuracy (lambda={LAMBDA_RIDGE}): {accuracy_score(y_test, y_pred_mkl):.4f}")

    # ---------------------------------------------------------
    # 7. Concatenated Baseline (ì´ì „ê³¼ ë™ì¼)
    # ---------------------------------------------------------
    print("\n--- 7. Concatenated Baseline ---")

    Xtr_concat = np.concatenate([X_train_features[n] for n in feature_names], axis=1)
    Xte_concat = np.concatenate([X_test_features[n] for n in feature_names], axis=1)

    svm_cat = SVC(kernel='linear')
    svm_cat.fit(Xtr_concat, y_train)
    y_pred_cat = svm_cat.predict(Xte_concat)
    print(f"Concat Accuracy: {accuracy_score(y_test, y_pred_cat):.4f}")

    # ---------------------------------------------------------
    # 8. [ìˆ˜ì •] ëª¨ë¸ ì €ì¥
    # ---------------------------------------------------------
    print("\n--- 8. ëª¨ë¸ ì €ì¥ ---")

    model_dir = os.path.join(base_dir, "models")
    os.makedirs(model_dir, exist_ok=True)

    model_data = {
        "svm_model": svm_model,
        "kernel_weights": d_raw,  # <--- raw ê°€ì¤‘ì¹˜ ì €ì¥
        "feature_names": feature_names,
        "kernel_functions": kernel_functions,
        "label_encoder": le,
        "scalers": scalers,
        "X_train_features": X_train_features,
        "mkl_type": "L2_Ridge" # MKL íƒ€ì… ëª…ì‹œ
    }

    save_path = os.path.join(model_dir, "l2_mkl_model.pkl")
    with open(save_path, "wb") as f:
        pickle.dump(model_data, f)

    print(f"ì €ì¥ ì™„ë£Œ: {save_path}")


# ============================================================
# ENTRY POINT
# ============================================================

if __name__ == "__main__":
    old_stdout = sys.stdout
    old_stderr = sys.stderr
    
    # [ìˆ˜ì •] print ì¶œë ¥ì„ ìœ„í•œ ë¦¬ë””ë ‰ì…˜ ì œê±° (ë””ë²„ê¹…/í™•ì¸ì„ ìœ„í•´)
    # redirected_output = io.StringIO()
    # sys.stdout = redirected_output
    # sys.stderr = redirected_output
    
    try:
        main()
    except Exception as e:
        sys.stdout = old_stdout
        sys.stderr = old_stderr
        print("âŒ ì—ëŸ¬ ë°œìƒ:")
        raise e

    sys.stdout = old_stdout
    sys.stderr = old_stderr

    # output = redirected_output.getvalue()
    # print(output)
    print("\n--- ğŸš€ ì‹¤í–‰ ì™„ë£Œ ---\n")