import os
import cv2
import pandas as pd
import numpy as np
from tqdm import tqdm
from skimage.feature import hog
from skimage.filters import gabor
from sklearn.model_selection import train_test_split
from sklearn.svm import SVC
from sklearn.metrics import accuracy_score
from sklearn.preprocessing import StandardScaler, LabelEncoder
from sklearn.metrics.pairwise import linear_kernel, rbf_kernel, chi2_kernel
import sys
import io
import pickle
import warnings
import matplotlib.pyplot as plt # ì‹œê°í™”ìš© (í•„ìš”ì‹œ)

# ê²½ê³  ë©”ì‹œì§€ ë¬´ì‹œ
warnings.filterwarnings('ignore')

# -----------------------------------------------------------------
# 1. í”¼ì³ ì¶”ì¶œ í•¨ìˆ˜ (ì œê³µëœ 5ê°œ ìŠ¤í¬ë¦½íŠ¸ ë¡œì§ í†µí•©)
# -----------------------------------------------------------------

def extract_hsv(img_bgr):
    """ (8, 8, 8) ë¹ˆì˜ 3D HSV íˆìŠ¤í† ê·¸ë¨ (512-dim)ì„ ë°˜í™˜í•©ë‹ˆë‹¤. """
    img_hsv = cv2.cvtColor(img_bgr, cv2.COLOR_BGR2HSV)
    hist = cv2.calcHist([img_hsv], [0, 1, 2], None, 
                        [8, 8, 8], [0, 180, 0, 256, 0, 256])
    # íˆìŠ¤í† ê·¸ë¨ì´ 0ì´ ë˜ëŠ” ê²ƒì„ ë°©ì§€ (chi2 ì»¤ë„ì„ ìœ„í•´)
    hist += 1e-6 
    cv2.normalize(hist, hist)
    return hist.flatten()

def extract_hog(img_bgr):
    """ 128x128ë¡œ ë¦¬ì‚¬ì´ì¦ˆëœ í‘ë°± ì´ë¯¸ì§€ì—ì„œ HOG í”¼ì³ (8100-dim)ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤. """
    img_gray = cv2.cvtColor(img_bgr, cv2.COLOR_BGR2GRAY)
    img_resized = cv2.resize(img_gray, (128, 128)) 
    feature_vector = hog(img_resized, pixels_per_cell=(8, 8),
                         cells_per_block=(2, 2), visualize=False)
    return feature_vector

def extract_sift_avg(img_bgr):
    """ SIFT ë””ìŠ¤í¬ë¦½í„°ì˜ í‰ê·  (128-dim)ì„ ë°˜í™˜í•©ë‹ˆë‹¤. """
    img_gray = cv2.cvtColor(img_bgr, cv2.COLOR_BGR2GRAY)
    try:
        sift = cv2.SIFT_create()
        kp, des = sift.detectAndCompute(img_gray, None)
        if des is not None and len(des) > 0:
            return np.mean(des, axis=0)
        else:
            return np.zeros(128)
    except cv2.error as e:
        print(" ! SIFT_create() ì—ëŸ¬. 'opencv-contrib-python'ì´ í•„ìš”í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.", file=sys.stderr)
        return np.zeros(128)
    except Exception as e:
        print(f" ! SIFT ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜: {e}", file=sys.stderr)
        return np.zeros(128)


def extract_orb_avg(img_bgr):
    """ ORB ë””ìŠ¤í¬ë¦½í„°ì˜ í‰ê·  (32-dim)ì„ ë°˜í™˜í•©ë‹ˆë‹¤. """
    img_gray = cv2.cvtColor(img_bgr, cv2.COLOR_BGR2GRAY)
    try:
        orb = cv2.ORB_create(nfeatures=500) # í‚¤í¬ì¸íŠ¸ ìˆ˜ ì§€ì •
        kp, des = orb.detectAndCompute(img_gray, None)
        if des is not None and len(des) > 0:
            return np.mean(des.astype(np.float32), axis=0)
        else:
            return np.zeros(32)
    except Exception as e:
        # print(f" ! ORB ìƒì„± ì‹¤íŒ¨: {e}", file=sys.stderr) # ì£¼ì„ ì²˜ë¦¬
        return np.zeros(32)

def compute_gist_gray(img_bgr: np.ndarray) -> np.ndarray:
    """ GIST-like í”¼ì³ (512-dim)ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤. """
    IMG_SIZE = 256
    N_BLOCKS = 4
    ORIENTATIONS_PER_SCALE = [8, 8, 8, 8]
    FREQUENCIES = [0.05, 0.10, 0.20, 0.40]
    
    img_gray = cv2.cvtColor(img_bgr, cv2.COLOR_BGR2GRAY)
    img_resized = cv2.resize(img_gray, (IMG_SIZE, IMG_SIZE)).astype(np.float32) / 255.0
    feats = []
    for freq, n_ori in zip(FREQUENCIES, ORIENTATIONS_PER_SCALE):
        for k in range(n_ori):
            theta = k * np.pi / n_ori
            real, imag = gabor(img_resized, frequency=freq, theta=theta)
            magnitude = np.sqrt(real ** 2 + imag ** 2)
            h, w = magnitude.shape
            bh, bw = h // N_BLOCKS, w // N_BLOCKS
            for by in range(N_BLOCKS):
                for bx in range(N_BLOCKS):
                    block = magnitude[by * bh:(by + 1) * bh, bx * bw:(bx + 1) * bw]
                    feats.append(block.mean())
    return np.asarray(feats, dtype=np.float32)

# -----------------------------------------------------------------
# 2. SimpleMKL í—¬í¼ í•¨ìˆ˜ (simpleMKL.pdf ê¸°ë°˜)
# -----------------------------------------------------------------

def compute_objective(alpha_y_sv, K_combined_sv):
    """SVM ë“€ì–¼ ëª©ì  í•¨ìˆ˜ J(d) ê³„ì‚° [cite: 215] (Equation 10)"""
    dual_obj_term = np.dot(alpha_y_sv, np.dot(K_combined_sv, alpha_y_sv))
    sum_alpha = np.sum(np.abs(alpha_y_sv)) # dual_coef_ëŠ” y*alpha ì´ë¯€ë¡œ sum(alpha)ëŠ” sum(abs(alpha_y_sv))
    
    # J(d) = sum(alpha) - 0.5 * ...
    return sum_alpha - 0.5 * dual_obj_term

def compute_gradient(alpha_y_sv, K_list_sv):
    """J(d)ì˜ ê²½ì‚¬(gradient) ê³„ì‚° [cite: 229] (Equation 11)"""
    M = len(K_list_sv)
    grad_J = np.zeros(M)
    for m in range(M):
        K_m_sv = K_list_sv[m]
        # dJ/dm = -0.5 * sum(alpha_i*alpha_j*y_i*y_j * K_m(i,j))
        grad_J[m] = -0.5 * np.dot(alpha_y_sv, np.dot(K_m_sv, alpha_y_sv))
    return grad_J

def compute_descent_direction(d, grad_J):
    """ì¶•ì†Œ ê²½ì‚¬(Reduced Gradient) ë° íˆ¬ì˜(Projection) ì ìš©  (Equation 12)"""
    M = len(d)
    # d_m ì¤‘ 0ì´ ì•„ë‹Œ ê°€ì¥ í° ê°’ì„ ê¸°ì¤€ìœ¼ë¡œ ì‚¬ìš© (ìˆ˜ì¹˜ì  ì•ˆì •ì„±)
    mu = np.argmax(d) 
    
    # 1. Reduced Gradient ê³„ì‚°
    reduced_grad = np.zeros(M)
    for m in range(M):
        if m != mu:
            reduced_grad[m] = grad_J[m] - grad_J[mu]
    
    # sum(D_m) = 0 ì œì•½ì¡°ê±´ì„ ë§Œì¡±ì‹œí‚¤ê¸° ìœ„í•¨
    reduced_grad[mu] = -np.sum(reduced_grad[np.arange(M) != mu])
    
    # 2. Descent Direction (D = -grad)
    D = -reduced_grad
    
    # 3. Projection (Positivity constraints)
    # d_m=0 ì´ê³  D_m < 0 (ê°ì†Œ ë°©í–¥)ì´ë©´, d_mì´ ìŒìˆ˜ê°€ ë˜ë¯€ë¡œ D_m=0ìœ¼ë¡œ ê°•ì œ
    for m in range(M):
        if d[m] < 1e-10 and D[m] < 0:
            D[m] = 0
            
    # sum(D_m) = 0 ì œì•½ì¡°ê±´ ë‹¤ì‹œ ì ìš©
    D[mu] = -np.sum(D[np.arange(M) != mu])
    return D

def backtracking_line_search(d, D, grad_J, K_list_train, y_train, C):
    """ë¼ì¸ ì„œì¹˜(Line Search)ë¡œ ìŠ¤í… ì‚¬ì´ì¦ˆ(gamma) íƒìƒ‰ [cite: 262]"""
    gamma = 1.0 # ìµœëŒ€ ìŠ¤í…
    alpha = 0.5 # ìŠ¤í… ê°ì†Œìœ¨
    beta = 0.1  # Armijo ì¡°ê±´ ì²´í¬ìš©
    
    current_J = compute_current_J(d, K_list_train, y_train, C)
    grad_dot_D = np.dot(grad_J, D)
    
    # í•˜ê°• ë°©í–¥ì´ ì•„ë‹ˆë©´ ì¤‘ë‹¨
    if grad_dot_D > 0:
        return 0
        
    while True:
        d_new = d + gamma * D
        
        # ìŠ¤í…ì´ ë„ˆë¬´ ì»¤ì„œ dê°€ ìŒìˆ˜ê°€ ë˜ë©´ gammaë¥¼ ì¤„ì„
        if np.any(d_new < 0):
            gamma *= alpha
            if gamma < 1e-10: return 0
            continue
            
        d_new /= np.sum(d_new) # ì‹¬í”Œë ‰ìŠ¤ ì œì•½ ì¡°ê±´ ë§Œì¡± (sum(d)=1)
        
        J_new = compute_current_J(d_new, K_list_train, y_train, C)
        
        # Armijo ì¡°ê±´: J(d + gamma*D) <= J(d) + beta * gamma * (grad_J . D)
        if J_new <= current_J + beta * gamma * grad_dot_D:
            return gamma # ì¡°ê±´ ë§Œì¡± ì‹œ ìŠ¤í… ë°˜í™˜
            
        gamma *= alpha # ì¡°ê±´ ë¶ˆë§Œì¡± ì‹œ ìŠ¤í… ê°ì†Œ
        
        if gamma < 1e-10:
            return 0 # ìŠ¤í…ì´ ë„ˆë¬´ ì‘ì•„ì§€ë©´ ì¤‘ë‹¨

def compute_current_J(d, K_list_train, y_train, C):
    """í˜„ì¬ dì— ëŒ€í•œ SVMì„ í’€ê³  ëª©ì  í•¨ìˆ˜ ê°’ J(d) ë°˜í™˜ [cite: 197-199]"""
    K_combined = np.zeros_like(K_list_train[0])
    for m in range(len(d)):
        K_combined += d[m] * K_list_train[m]
        
    svm = SVC(kernel='precomputed', C=C, tol=1e-5, probability=True, cache_size=500)
    svm.fit(K_combined, y_train)
    
    sv_indices = svm.support_
    if len(sv_indices) == 0:
        return 0 # ì„œí¬íŠ¸ ë²¡í„°ê°€ ì—†ëŠ” ê²½ìš°
        
    # alpha_y_sv = y_i * alpha_i (for support vectors)
    alpha_y_sv = svm.dual_coef_[0] 
    
    # ì„œí¬íŠ¸ ë²¡í„°ì— í•´ë‹¹í•˜ëŠ” ì»¤ë„ ë¶€ë¶„ë§Œ ì¶”ì¶œ
    K_combined_sv = K_combined[np.ix_(sv_indices, sv_indices)]
    
    J_d = compute_objective(alpha_y_sv, K_combined_sv)
    return J_d

# -----------------------------------------------------------------
# 3. SimpleMKL ë©”ì¸ í›ˆë ¨ ì•Œê³ ë¦¬ì¦˜
# -----------------------------------------------------------------
def simple_mkl_train(K_list_train, y_train, C=1.0, max_iter=100, tol=1e-3):
    """SimpleMKL Algorithm 1 êµ¬í˜„ """
    M = len(K_list_train) # ì»¤ë„ì˜ ìˆ˜
    n_train = K_list_train[0].shape[0] # í›ˆë ¨ ìƒ˜í”Œ ìˆ˜
    
    # 1. d ì´ˆê¸°í™”
    d = np.ones(M) / M
    svm_model = None 
    
    for i in range(max_iter):
        # 2. í˜„ì¬ dë¡œ ê²°í•©ëœ ì»¤ë„ K ê³„ì‚°
        K_combined_train = np.zeros((n_train, n_train))
        for m in range(M):
            K_combined_train += d[m] * K_list_train[m]
            
        # 3. Kë¡œ SVM í›ˆë ¨ (J(d) ê³„ì‚°ì„ ìœ„í•´)
        svm = SVC(kernel='precomputed', C=C, tol=1e-5, probability=True, cache_size=500)
        svm.fit(K_combined_train, y_train)
        
        sv_indices = svm.support_
        if len(sv_indices) == 0:
            print(f"ë°˜ë³µ {i+1}íšŒ: ì„œí¬íŠ¸ ë²¡í„°ê°€ ì—†ìŠµë‹ˆë‹¤. í›ˆë ¨ ì¤‘ë‹¨.")
            svm_model = svm
            break
            
        # y_i * alpha_i
        alpha_y_sv = svm.dual_coef_[0]
        
        # 4. dJ/dm (ê·¸ë˜ë””ì–¸íŠ¸) ê³„ì‚°
        K_list_sv = [K_m[np.ix_(sv_indices, sv_indices)] for K_m in K_list_train]
        grad_J = compute_gradient(alpha_y_sv, K_list_sv)
        
        # 5. ì¢…ë£Œ ì¡°ê±´ í™•ì¸ (Duality Gap)
        # Q = -grad_J
        # Gap = max(Q) - (d . Q)
        Q = -grad_J
        gap = np.max(Q) - np.dot(d, Q)
        
        if gap < tol:
            print(f"ë°˜ë³µ {i+1}íšŒ: ìµœì í•´ ë„ë‹¬ (Duality Gap < {tol}).")
            svm_model = svm
            break
            
        # 6. í•˜ê°• ë°©í–¥ D ê³„ì‚°
        D = compute_descent_direction(d, grad_J)
        
        if np.allclose(D, 0):
            print(f"ë°˜ë³µ {i+1}íšŒ: í•˜ê°• ë°©í–¥ì´ 0, ìµœì í•´ ë„ë‹¬.")
            svm_model = svm
            break

        # 7. ë¼ì¸ ì„œì¹˜ë¡œ ìŠ¤í… ì‚¬ì´ì¦ˆ gamma ê²°ì •
        gamma = backtracking_line_search(d, D, grad_J, K_list_train, y_train, C)
        
        if gamma == 0:
            print(f"ë°˜ë³µ {i+1}íšŒ: ìŠ¤í… ì‚¬ì´ì¦ˆê°€ 0, ìµœì í•´ ë„ë‹¬.")
            svm_model = svm
            break
            
        # 8. d ì—…ë°ì´íŠ¸
        d = d + gamma * D
        d[d < 0] = 0      # ìŒìˆ˜ ë°©ì§€
        d /= np.sum(d)  # ì •ê·œí™” (sum(d)=1)
        
        print(f"ë°˜ë³µ {i+1}/{max_iter}: Gap={gap:.4f}, d={[round(x, 3) for x in d]}")

    if svm_model is None:
        svm_model = svm
        print("ìµœëŒ€ ë°˜ë³µ íšŸìˆ˜ì— ë„ë‹¬í–ˆìŠµë‹ˆë‹¤.")
        
    return svm_model, d

# -----------------------------------------------------------------
# 4. ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜
# -----------------------------------------------------------------
def main():
    print("--- 1. ë°ì´í„° ì¤€ë¹„ (ë””ë ‰í† ë¦¬ êµ¬ì¡° ê¸°ë°˜) ---")
    
    # [ìˆ˜ì •] ìŠ¤í¬ë¦½íŠ¸ ìœ„ì¹˜ ë° ë°ì´í„° í´ë” ê²½ë¡œ ì„¤ì •
    try:
        current_script_path = os.path.abspath(__file__)
        base_dir = os.path.dirname(current_script_path) # ML_5gwarts í´ë”
    except NameError:
        # e.g., Jupyter ë…¸íŠ¸ë¶ì—ì„œ ì‹¤í–‰ ì‹œ __file__ì´ ì—†ìŒ
        base_dir = os.path.abspath(os.getcwd())
        
    # [ìˆ˜ì •] ì´ë¯¸ì§€ì˜ 'train' ë””ë ‰í† ë¦¬ ì‚¬ìš©
    data_root_dir = os.path.join(base_dir, "train") 
    
    if not os.path.exists(data_root_dir):
        print(f" ! ì—ëŸ¬: '{data_root_dir}' ë””ë ‰í† ë¦¬ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        print(f"   ì˜ˆìƒ ìŠ¤í¬ë¦½íŠ¸ ìœ„ì¹˜: {base_dir}")
        print("   ìŠ¤í¬ë¦½íŠ¸ê°€ 'ML_5gwarts' í´ë”ì— ìˆëŠ”ì§€, 'train' í´ë”ê°€ ìˆëŠ”ì§€ í™•ì¸í•˜ì„¸ìš”.")
        return

    # í”¼ì³ ì¶”ì¶œ í•¨ìˆ˜ ë§µí•‘
    feature_extractors = {
        'hsv': extract_hsv,
        'hog': extract_hog,
        'sift_avg': extract_sift_avg,
        'orb_avg': extract_orb_avg,
        'gist': compute_gist_gray
    }
    
    # ì»¤ë„ í•¨ìˆ˜ ë§µí•‘ (í”¼ì³ë§ˆë‹¤ ë‹¤ë¥¸ ì»¤ë„ì„ ì§€ì •)
    kernel_functions = {
        'hsv': chi2_kernel, # íˆìŠ¤í† ê·¸ë¨ì´ë¯€ë¡œ chi2
        'hog': linear_kernel,
        'sift_avg': linear_kernel,
        'orb_avg': linear_kernel,
        'gist': linear_kernel
    }
    
    feature_names = list(feature_extractors.keys())
    print(f"ì‚¬ìš©í•  í”¼ì³ ë””ìŠ¤í¬ë¦½í„°: {feature_names}")

    # --- 2. ì´ë¯¸ì§€ ë¡œë“œ ë° í”¼ì³ ì¶”ì¶œ ---
    print("\n--- 2. ì´ë¯¸ì§€ ë¡œë“œ ë° í”¼ì³ ì¶”ì¶œ ---")
    
    all_labels = []
    all_images = []
    
    # [ìˆ˜ì •] 'train' í´ë”ì˜ í•˜ìœ„ í´ë”(1F1N, 1F2N...)ë¥¼ ë ˆì´ë¸”ë¡œ ì‚¬ìš©
    for label_name in sorted(os.listdir(data_root_dir)):
        zone_path = os.path.join(data_root_dir, label_name)
        if not os.path.isdir(zone_path):
            continue
        print(f"  [Zone ë¡œë“œ ì¤‘: {label_name}]")
        for img_name in tqdm(os.listdir(zone_path), desc=label_name):
            img_path = os.path.join(zone_path, img_name)
            img_bgr = cv2.imread(img_path)
            if img_bgr is not None:
                # [ìˆ˜ì •] ì›ë³¸ ì´ë¯¸ì§€ë¥¼ ê·¸ëŒ€ë¡œ ì¶”ê°€ (ê° ì¶”ì¶œ í•¨ìˆ˜ê°€ ë¦¬ì‚¬ì´ì§• ë‹´ë‹¹)
                all_images.append(img_bgr)
                all_labels.append(label_name)
            else:
                print(f" ! ê²½ê³ : {img_path} ë¡œë“œ ì‹¤íŒ¨")

    if not all_images:
        print(f" ! ì—ëŸ¬: '{data_root_dir}' í´ë”ì—ì„œ ì´ë¯¸ì§€ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        return

    # ë ˆì´ë¸”ì„ ìˆ«ìë¡œ ë³€í™˜ (e.g., "1F1N" -> 0)
    le = LabelEncoder()
    y_labels = le.fit_transform(all_labels)
    print(f"\nì´ {len(all_images)}ê°œ ì´ë¯¸ì§€ ë¡œë“œ ì™„ë£Œ.")
    print(f"í´ë˜ìŠ¤: {le.classes_} ({len(le.classes_)}ê°œ)")

    # í›ˆë ¨ / í…ŒìŠ¤íŠ¸ ë°ì´í„° ë¶„ë¦¬
    X_train_imgs, X_test_imgs, y_train, y_test = train_test_split(
        all_images, y_labels, test_size=0.3, random_state=42, stratify=y_labels
    )
    print(f"í›ˆë ¨ ì´ë¯¸ì§€: {len(X_train_imgs)}ê°œ, í…ŒìŠ¤íŠ¸ ì´ë¯¸ì§€: {len(X_test_imgs)}ê°œ")
    
    # ë©”ëª¨ë¦¬ í™•ë³´ (ì›ë³¸ ì´ë¯¸ì§€ ë¦¬ìŠ¤íŠ¸ ì‚­ì œ)
    del all_images
    del all_labels

    # ëª¨ë“  í”¼ì³ ì¶”ì¶œ
    X_train_features = {name: [] for name in feature_names}
    X_test_features = {name: [] for name in feature_names}
    scalers = {} # í”¼ì³ë³„ ìŠ¤ì¼€ì¼ëŸ¬ ì €ì¥

    print("í›ˆë ¨ ë°ì´í„° í”¼ì³ ì¶”ì¶œ ì¤‘...")
    for img in tqdm(X_train_imgs, desc="Train Extract"):
        for name, func in feature_extractors.items():
            X_train_features[name].append(func(img))
            
    print("í…ŒìŠ¤íŠ¸ ë°ì´í„° í”¼ì³ ì¶”ì¶œ ì¤‘...")
    for img in tqdm(X_test_imgs, desc="Test Extract"):
        for name, func in feature_extractors.items():
            X_test_features[name].append(func(img))
    
    # ë©”ëª¨ë¦¬ í™•ë³´ (í›ˆë ¨/í…ŒìŠ¤íŠ¸ ì´ë¯¸ì§€ ë¦¬ìŠ¤íŠ¸ ì‚­ì œ)
    del X_train_imgs
    del X_test_imgs

    # Numpy ë°°ì—´ ë³€í™˜ ë° ì •ê·œí™”
    for name in feature_names:
        X_train_features[name] = np.array(X_train_features[name])
        X_test_features[name] = np.array(X_test_features[name])
        
        scaler = StandardScaler().fit(X_train_features[name])
        X_train_features[name] = scaler.transform(X_train_features[name])
        X_test_features[name] = scaler.transform(X_test_features[name])
        scalers[name] = scaler # ìŠ¤ì¼€ì¼ëŸ¬ ì €ì¥

    # --- 3. ê°œë³„ ì»¤ë„ ê³„ì‚° ---
    print("\n--- 3. ê°œë³„ ì»¤ë„ ê³„ì‚° ---")
    K_list_train = [] # í›ˆë ¨ ì»¤ë„ (Train-Train)
    K_list_test = []  # í…ŒìŠ¤íŠ¸ ì»¤ë„ (Test-Train)
    
    for name in feature_names:
        print(f"  - {name} ì»¤ë„ ê³„ì‚° (ì»¤ë„: {kernel_functions[name].__name__})...")
        X_train = X_train_features[name]
        X_test = X_test_features[name]
        
        kernel_func = kernel_functions[name]
        
        # chi2 ì»¤ë„ì€ ìŒìˆ˜ ê°’ì„ ì²˜ë¦¬í•˜ì§€ ëª»í•¨
        if kernel_func == chi2_kernel:
            # StandardScalerë¡œ ì¸í•´ ìŒìˆ˜ê°€ ëœ ê°’ì„ ì–‘ìˆ˜í™”
            min_val_train = X_train.min()
            if min_val_train <= 0:
                X_train += -min_val_train + 1e-6 # 0 ë°©ì§€ë¥¼ ìœ„í•´ 1e-6 ë”í•¨
            
            min_val_test = X_test.min()
            if min_val_test <= 0:
                X_test += -min_val_test + 1e-6
        
        K_list_train.append(kernel_func(X_train, X_train))
        K_list_test.append(kernel_func(X_test, X_train)) # <--- ì¤‘ìš”: K_test(X_test, X_train)

    # --- 4. SimpleMKL í›ˆë ¨ ë° ì˜ˆì¸¡ ---
    print("\n--- 4. SimpleMKL í›ˆë ¨ ì‹œì‘ ---")
    C_value = 1.0 
    
    final_svm_model, optimal_d = simple_mkl_train(K_list_train, y_train, C=C_value, max_iter=200, tol=1e-4)

    print("-" * 50)
    print(f"í›ˆë ¨ ì™„ë£Œ.")
    print(f"ìµœì ì˜ ì»¤ë„ ê°€ì¤‘ì¹˜ (d):")
    for i in range(len(optimal_d)):
        print(f"  {feature_names[i]:<10}: {optimal_d[i]:.4f}")
    print("-" * 50)

    print("SimpleMKL ì˜ˆì¸¡ ìˆ˜í–‰...")
    
    # K_test_combined = sum(d_m * K_m_test)
    K_combined_test = np.zeros_like(K_list_test[0])
    for m in range(len(optimal_d)):
        K_combined_test += optimal_d[m] * K_list_test[m]
    
    # í›ˆë ¨ëœ SVM ëª¨ë¸(final_svm_model)ì€ 'precomputed' ì»¤ë„ì„ ì‚¬ìš©
    y_pred_mkl = final_svm_model.predict(K_combined_test)
    print(f"âœ… SimpleMKL ì •í™•ë„: {accuracy_score(y_test, y_pred_mkl):.4f}")
    print("-" * 50)

    # --- 5. (ë¹„êµ) ë‚˜ì´ë¸Œí•œ ê²°í•© (Concatenation) ë°©ì‹ ---
    print("--- 5. (ë¹„êµ) ë‚˜ì´ë¸Œí•œ í”¼ì³ ê²°í•© (Concatenate) ìˆ˜í–‰ ---")
    
    X_train_concat = np.concatenate([X_train_features[name] for name in feature_names], axis=1)
    X_test_concat = np.concatenate([X_test_features[name] for name in feature_names], axis=1)
    
    print(f"ë‚˜ì´ë¸Œ ê²°í•© í”¼ì³ ì°¨ì›: {X_train_concat.shape[1]}")

    svm_concat = SVC(kernel='linear', C=C_value)
    svm_concat.fit(X_train_concat, y_train)
    y_pred_concat = svm_concat.predict(X_test_concat)

    print(f"âœ… ë‚˜ì´ë¸Œ ê²°í•© ì •í™•ë„: {accuracy_score(y_test, y_pred_concat):.4f}")
    print("-" * 50)
    
    # --- 6. ëª¨ë¸ ì €ì¥ ---
    print("--- 6. ìµœì¢… ëª¨ë¸ ì €ì¥ ---")
    model_output_dir = os.path.join(base_dir, "models")
    os.makedirs(model_output_dir, exist_ok=True)
    
    # MKL ëª¨ë¸ ì €ì¥ì€ SVM ëª¨ë¸ ì™¸ì—ë„ ë§ì€ ì •ë³´ê°€ í•„ìš”í•¨
    mkl_model_data = {
        'svm_model': final_svm_model,       # í›ˆë ¨ëœ SVC ê°ì²´
        'kernel_weights': optimal_d,      # ì»¤ë„ ê°€ì¤‘ì¹˜ d
        'feature_names': feature_names,   # í”¼ì³ ì´ë¦„ ë¦¬ìŠ¤íŠ¸
        'kernel_functions': kernel_functions, # ì‚¬ìš©ëœ ì»¤ë„ í•¨ìˆ˜ ë§µ
        'label_encoder': le,              # ë ˆì´ë¸” ì¸ì½”ë”
        'scalers': scalers,               # í”¼ì³ë³„ ìŠ¤ì¼€ì¼ëŸ¬
        'X_train_features': X_train_features # ì˜ˆì¸¡ ì‹œ K_test ê³„ì‚°ì— í•„ìš”
    }
    
    model_path = os.path.join(model_output_dir, "simple_mkl_model.pkl")
    with open(model_path, 'wb') as f:
        pickle.dump(mkl_model_data, f)
    print(f"MKL ëª¨ë¸ ë°ì´í„° ì €ì¥ ì™„ë£Œ: {model_path}")


if __name__ == "__main__":
    # í‘œì¤€ ì¶œë ¥ì„ io.StringIO ê°ì²´ë¡œ ë¦¬ë””ë ‰ì…˜ (printë¬¸ ìº¡ì²˜ìš©)
    old_stdout = sys.stdout
    old_stderr = sys.stderr
    redirected_output = io.StringIO()
    sys.stdout = redirected_output
    sys.stderr = redirected_output
    
    try:
        main()
    except Exception as e:
        # ì—ëŸ¬ ë°œìƒ ì‹œ í‘œì¤€ ì¶œë ¥/ì—ëŸ¬ ë³µì›
        sys.stdout = old_stdout
        sys.stderr = old_stderr
        print(f"\n--- ğŸš« ìŠ¤í¬ë¦½íŠ¸ ì‹¤í–‰ ì¤‘ ì—ëŸ¬ ë°œìƒ ---")
        # ìº¡ì²˜ëœ ì¶œë ¥ ì¸ì‡„
        output = redirected_output.getvalue()
        print(output)
        # ì—ëŸ¬ íŠ¸ë ˆì´ìŠ¤ë°± ì¸ì‡„
        raise e
    
    # ì„±ê³µ ì‹œ í‘œì¤€ ì¶œë ¥/ì—ëŸ¬ ë³µì›
    sys.stdout = old_stdout
    sys.stderr = old_stderr
    
    # ìº¡ì²˜ëœ ëª¨ë“  ì¶œë ¥ì„ ë§ˆì§€ë§‰ì— í•œ ë²ˆì— ì¸ì‡„
    output = redirected_output.getvalue()
    print("--- ğŸš€ ìŠ¤í¬ë¦½íŠ¸ ì‹¤í–‰ ì™„ë£Œ ---")
    print(output)